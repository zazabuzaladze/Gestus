{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689cd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python --version\n",
    "#nötig ist version 3.8.17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa77715",
   "metadata": {},
   "source": [
    "## Bibliotheken, die ich benutze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527ba62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp    #model erstellen\n",
    "import numpy as np        #mit arrays arbeiten\n",
    "import os                 #mit dem Dateisystem interagieren\n",
    "import sklearn            #für confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3cb1f",
   "metadata": {},
   "source": [
    "## Datensatz vorbereiten und Labels und Features erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e153a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deutschland', 'frieden', 'hallo', 'liebe', 'praesentation', 'wettbewerb']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split       #datensatz teilen für testen und trainieren\n",
    "from tensorflow.keras.utils import to_categorical          \n",
    "\n",
    "# Liste aller Gesten abrufen\n",
    "# https://www.geeksforgeeks.org/python-list-files-in-a-directory/\n",
    "\n",
    "path = os.path.join('datensatz1')\n",
    "gesten_list = os.listdir(path)\n",
    "\n",
    "gesten = np.array(gesten_list)\n",
    "#np array ist später nötig für trainieren\n",
    " \n",
    "print(gesten_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bee739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deutschland': 0, 'frieden': 1, 'hallo': 2, 'liebe': 3, 'praesentation': 4, 'wettbewerb': 5}\n"
     ]
    }
   ],
   "source": [
    "#liste in der dictionary umwandeln und numarieren\n",
    "\n",
    "label_map = {}\n",
    "n = 0\n",
    "\n",
    "for label in gesten_list:\n",
    "    label_map[gesten_list[n]] = n\n",
    "    n += 1\n",
    "    \n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77b0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wir müssen hier anpassen mithilfe von unsere datensatz, wie viele videos wir pro geste aufgenommen haben und wie viele frame hat jede video\n",
    "num_videos = 40\n",
    "vid_length = 20   #frame\n",
    "\n",
    "#mein datensatz verzeichnis\n",
    "DATA_PATH = os.path.join('datensatz1')\n",
    "\n",
    "videos = []\n",
    "labels = []\n",
    "\n",
    "#alle videos k-points in eine array zusammenfassen\n",
    "\n",
    "for geste in gesten:\n",
    "    for vid in range(num_videos):\n",
    "        window = []\n",
    "        for frame_num in range(vid_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, geste, str(vid), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        videos.append(window)\n",
    "        labels.append(label_map[geste])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e8e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umwandeln in numpy array\n",
    "#kp = k-points\n",
    "kp = np.array(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c295cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gn = geste_name\n",
    "gn = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe45ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datensatz teilen in test- und trainierenteil\n",
    "\n",
    "kp_train, kp_test, gn_train, gn_test = train_test_split(kp, gn, test_size=0.05)    #test teil ist 5% von unsere datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7c84f",
   "metadata": {},
   "source": [
    "## LSTM Neuronales Netz aufbauen und trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e94e7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=doDUihpj6ro&list=PLyx6mI41rWldgZWHzHBGBQfP5MxFQNcFf&index=5&ab_channel=NicholasRenotte\n",
    "#https://www.youtube.com/watch?v=tPYj3fFJGjk&list=PLyx6mI41rWldgZWHzHBGBQfP5MxFQNcFf&index=1&ab_channel=freeCodeCamp.org    #2:45:41\n",
    "#https://www.youtube.com/watch?v=jmmW0F0biz0&ab_channel=IBMTechnology\n",
    "#https://www.youtube.com/watch?v=aircAruvnKk&ab_channel=3Blue1Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc42fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "#Die sequentielle ist nützlicher als die funktionale, da wir eine Dateneingabe und eine Datenausgabe haben.\n",
    "#Es leitet die Daten weiter und fließt in sequentieller Reihenfolge von oben nach unten, bis die Daten am Ende des Modells ankommen.\n",
    "#https://www.educba.com/keras-sequential/\n",
    "#https://www.youtube.com/watch?v=8uC-WT1LYnU&ab_channel=Simplilearn\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "#LSTM Layer: ermöglicht uns die Erkennung von Aktionen\n",
    "#Keras Dense-Schicht ist die Schicht, die alle Neuronen enthält, die in sich selbst tief verbunden sind. Das bedeutet, dass jedes Neuron in der dichten Schicht die Eingabe von allen anderen Neuronen der vorherigen Schicht erhält. Wir können so viele dichte Schichten wie nötig hinzufügen. Sie ist eine der am häufigsten verwendeten Schichten.\n",
    "#https://www.educba.com/keras-dense/\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "#unser Training im echtzeit überwachen (von CMD anschalten)\n",
    "#https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b0bb5d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#unser Training zu überwachen\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m tb_callback \u001b[38;5;241m=\u001b[39m TensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#unser Training zu überwachen\n",
    "\n",
    "log_dir = os.path.join(\"Logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)   #siehe \"Tensorboard CMD.txt\" datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d2f7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(20, 258)))\n",
    "#64 LSTM Units     \n",
    "#return sequences = True: weil die nächste Schicht dies braucht\n",
    "#activation = relu: Funktion, die die Eingabe direkt ausgibt, wenn sie positiv ist, andernfalls gibt sie Null aus.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "#return sequences = False: weil die nächste Schicht ist Dense layer/schicht\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "#letzte Schicht\n",
    "model.add(Dense(gesten.shape[0], activation='softmax'))\n",
    "#Softmax ist eine Aktivierungsfunktion, die Zahlen/Logits in Wahrscheinlichkeiten umwandelt. \n",
    "#Die Ausgabe einer Softmax-Funktion ist ein Vektor (z. B. v) mit Wahrscheinlichkeiten für jedes mögliche Ergebnis. \n",
    "#Die Wahrscheinlichkeiten im Vektor v summieren sich für alle möglichen Ergebnisse oder Klassen zu eins.\n",
    "#https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f21ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell kompilieren\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#optimizer=\"Adam\" : Dieser Algorithmus ist rechnerisch effizient, benötigt wenig Speicherplatz, ist invariant gegenüber einer diagonalen Skalierung der Gradienten und eignet sich gut für Probleme, die hinsichtlich der Daten/Parameter sehr groß sind.\n",
    "#https://keras.io/api/optimizers/adam/\n",
    "#loss='categorical_crossentropy': Wir müssen \"categorical_crossentropy\" Funktion verwenden, weil wir ein (/multi-)Mehrklassen-Klassifizierungsmodell(siehe oben test1) und kein binäres Klassifizierungsmodell(0 oder 1) haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d49e589d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "8/8 [==============================] - 8s 51ms/step - loss: 1.7752 - categorical_accuracy: 0.1711\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 1.6713 - categorical_accuracy: 0.4298\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 1.3759 - categorical_accuracy: 0.3509\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.0168 - categorical_accuracy: 0.5526\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.7764 - categorical_accuracy: 0.6404\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.4501 - categorical_accuracy: 0.8509\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1406 - categorical_accuracy: 0.6711\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.8903 - categorical_accuracy: 0.6404\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.0914 - categorical_accuracy: 0.6491\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.8247 - categorical_accuracy: 0.6798\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4909 - categorical_accuracy: 0.8070\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.4815 - categorical_accuracy: 0.8026\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.3682 - categorical_accuracy: 0.8860\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5750 - categorical_accuracy: 0.7807\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.9325 - categorical_accuracy: 0.7851\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.5715 - categorical_accuracy: 0.3465\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.5351 - categorical_accuracy: 0.3772\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 1.2561 - categorical_accuracy: 0.5219\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.9755 - categorical_accuracy: 0.8070\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6412 - categorical_accuracy: 0.7412\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4394 - categorical_accuracy: 0.8289\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 4.9813 - categorical_accuracy: 0.3684\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 1.3282 - categorical_accuracy: 0.3816\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.4467 - categorical_accuracy: 0.4868\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.3381 - categorical_accuracy: 0.5175\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 1.0349 - categorical_accuracy: 0.4956\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.3154 - categorical_accuracy: 0.3904\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4712 - categorical_accuracy: 0.3246\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.4625 - categorical_accuracy: 0.3684\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 1.1417 - categorical_accuracy: 0.6623\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.5556 - categorical_accuracy: 0.7807\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.5974 - categorical_accuracy: 0.7675\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.8522 - categorical_accuracy: 0.6360\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5911 - categorical_accuracy: 0.8333\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.3088 - categorical_accuracy: 0.8904\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1860 - categorical_accuracy: 0.9167\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.3639 - categorical_accuracy: 0.8860\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4150 - categorical_accuracy: 0.7982\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2742 - categorical_accuracy: 0.8947\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.1096 - categorical_accuracy: 0.9825\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3379 - categorical_accuracy: 0.8684\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.2959 - categorical_accuracy: 0.9079\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1775 - categorical_accuracy: 0.9561\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0854 - categorical_accuracy: 0.9693\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4800 - categorical_accuracy: 0.8377\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3343 - categorical_accuracy: 0.8904\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1285 - categorical_accuracy: 0.9474\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0666 - categorical_accuracy: 0.9781\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.1000 - categorical_accuracy: 0.9825\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3184 - categorical_accuracy: 0.8904\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.2831 - categorical_accuracy: 0.9430\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.1658 - categorical_accuracy: 0.9386\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1103 - categorical_accuracy: 0.9649\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0745 - categorical_accuracy: 0.9737\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0499 - categorical_accuracy: 0.9868\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0303 - categorical_accuracy: 0.9956\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0194 - categorical_accuracy: 0.9956\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0172 - categorical_accuracy: 0.9956\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0118 - categorical_accuracy: 0.9956\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0102 - categorical_accuracy: 0.9956\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0098 - categorical_accuracy: 0.9956\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0074 - categorical_accuracy: 0.9956\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0071 - categorical_accuracy: 0.9956\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0055 - categorical_accuracy: 0.9956\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.0043 - categorical_accuracy: 0.9956\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0033 - categorical_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.0027 - categorical_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0022 - categorical_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.0017 - categorical_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.0014 - categorical_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.0013 - categorical_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 9.6225e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 8.4680e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 6.7082e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.8412e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 5.0676e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 4.4601e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.8931e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 3.4607e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 3.1687e-04 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d337868b20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model trainieren\n",
    "\n",
    "model.fit(kp_train, gn_train, epochs=80, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a2350f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 64)            82688     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237350 (927.15 KB)\n",
      "Trainable params: 237350 (927.15 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#aussehen von unsere model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10892a25",
   "metadata": {},
   "source": [
    "## Vorhersagen treffen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6591733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b06c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 837ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(kp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a7737e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'praesentation'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesten[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a080ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'praesentation'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gesten[np.argmax(gn_test[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5342c2",
   "metadata": {},
   "source": [
    "### Confusion matrix + Genauigkeitsgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57974da",
   "metadata": {},
   "source": [
    "Eine Confusion matrix stellt die Zusammenfassung der Vorhersagen in Form einer Matrix dar. Sie zeigt, wie viele Vorhersagen pro Klasse richtig und falsch sind.\n",
    "\n",
    "https://www.sciencedirect.com/topics/engineering/confusion-matrix#:~:text=A%20confusion%20matrix%20represents%20the,by%20model%20as%20other%20class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "597d147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbc4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(kp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4618d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(gn_train, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81ffb9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[190,   0],\n",
       "        [  0,  38]],\n",
       "\n",
       "       [[190,   0],\n",
       "        [  0,  38]],\n",
       "\n",
       "       [[191,   0],\n",
       "        [  0,  37]],\n",
       "\n",
       "       [[190,   0],\n",
       "        [  0,  38]],\n",
       "\n",
       "       [[191,   0],\n",
       "        [  0,  37]],\n",
       "\n",
       "       [[188,   0],\n",
       "        [  0,  40]]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)\n",
    "#[[True N, False P],\n",
    "# [False N, True P]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73a9bcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69aed9",
   "metadata": {},
   "source": [
    "## Gewichte/Weights sichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b386ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaza0\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"gesten1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d20ccce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modell löschen\n",
    "# del model\n",
    "\n",
    "#load model\n",
    "# model.load_Weights(\"action.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf6716",
   "metadata": {},
   "source": [
    "# Quellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff759e",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=doDUihpj6ro&list=PLyx6mI41rWldgZWHzHBGBQfP5MxFQNcFf&index=5&ab_channel=NicholasRenotte\n",
    "https://www.geeksforgeeks.org/python-list-files-in-a-directory/#\n",
    "https://www.youtube.com/watch?v=doDUihpj6ro&list=PLyx6mI41rWldgZWHzHBGBQfP5MxFQNcFf&index=5&ab_channel=NicholasRenotte\n",
    "https://www.youtube.com/watch?v=tPYj3fFJGjk&list=PLyx6mI41rWldgZWHzHBGBQfP5MxFQNcFf&index=1&ab_channel=freeCodeCamp.org    \n",
    "https://www.youtube.com/watch?v=jmmW0F0biz0&ab_channel=IBMTechnology\n",
    "https://www.youtube.com/watch?v=aircAruvnKk&ab_channel=3Blue1Brown\n",
    "https://www.educba.com/keras-sequential/\n",
    "https://www.youtube.com/watch?v=8uC-WT1LYnU&ab_channel=Simplilearn\n",
    "https://www.educba.com/keras-dense/\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "https://www.tensorflow.org/tensorboard/get_started\n",
    "https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78\n",
    "https://keras.io/api/optimizers/adam/\n",
    "https://www.sciencedirect.com/topics/engineering/confusion-matrix#:~:text=A%20confusion%20matrix%20represents%20the,by%20model%20as%20other%20class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0d5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
